{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ed463-5774-47a5-a15a-9771e5c368b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.embed import json_item\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import dodge\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.dataset.vtt import CATEGORIES, TOPICS, VTTDataset  # noqa: E402\n",
    "from src.utils.datatool import read_json, read_jsonlines  # noqa: E402\n",
    "from src.utils.plottool import matplotlib_header  # noqa: E402\n",
    "\n",
    "dataset = VTTDataset(\n",
    "    \"test\", return_raw_text=True, transform_cfg={\"normalize\": False}\n",
    ")\n",
    "\n",
    "\n",
    "LOG_ROOT = \"/log/exp/vtt/\"\n",
    "details_cache = {}\n",
    "exp_ids_cache = {}\n",
    "results_cache = {}\n",
    "\n",
    "def get_exp_ids():\n",
    "    exp_names = []\n",
    "    for exp_root in sorted(Path(LOG_ROOT).glob(\"*\")):\n",
    "        if (exp_root / \"detail.jsonl\").exists():\n",
    "            config = OmegaConf.load(exp_root / \"config.yaml\")\n",
    "            exp_name = config.name\n",
    "            exp_id = exp_root.name\n",
    "            exp_time = exp_id.split(\".\")[-1]\n",
    "            i = 1\n",
    "            while True:\n",
    "                if (\n",
    "                    exp_name in exp_ids_cache\n",
    "                    and exp_ids_cache[exp_name] != exp_id\n",
    "                ):\n",
    "                    exp_name = f\"{config.name}_{i}\"\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "            exp_ids_cache[exp_name] = exp_id\n",
    "            exp_names.append((exp_name, exp_time))\n",
    "\n",
    "            summary_path = (\n",
    "                exp_root\n",
    "                / \"wandb\"\n",
    "                / \"latest-run\"\n",
    "                / \"files\"\n",
    "                / \"wandb-summary.json\"\n",
    "            )\n",
    "            if summary_path.exists():\n",
    "                results_cache[exp_name] = read_json(summary_path)\n",
    "    exp_names = [\n",
    "        x[0] for x in sorted(exp_names, key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return exp_names\n",
    "\n",
    "\n",
    "def index2result(index, exp_names=[]):\n",
    "    index = max(0, min(int(index), len(dataset) - 1))\n",
    "    data = dataset[index]\n",
    "    text_table = get_text_table(index, data, exp_names)\n",
    "    metrics_plot = get_metrics_pyplot(index, exp_names)\n",
    "    # metrics_plot = get_metrics_bokeh(index, exp_names)\n",
    "    metrics_table = get_metrics_table(index, exp_names)\n",
    "    pred_classification_table = get_classification_table(index, exp_names)\n",
    "    overall_metrics_plot = get_overall_metrics_pyplot(exp_names)\n",
    "    overall_metrics_table = get_overall_metrics_table(exp_names)\n",
    "    return (\n",
    "        index,\n",
    "        CATEGORIES[data[\"category\"]],\n",
    "        TOPICS[data[\"topic\"]],\n",
    "        cache_test_image(data),\n",
    "        text_table,\n",
    "        metrics_plot,\n",
    "        metrics_table,\n",
    "        pred_classification_table,\n",
    "        overall_metrics_plot,\n",
    "        overall_metrics_table,\n",
    "    )\n",
    "\n",
    "\n",
    "def random_result(exp_names=[]):\n",
    "    index = np.random.randint(len(dataset))\n",
    "    return index2result(index, exp_names)\n",
    "\n",
    "\n",
    "def cache_test_image(data, cache_dir=\"/data/vtt/cache/\"):\n",
    "    cache_dir = Path(cache_dir)\n",
    "    cache_dir.mkdir(exist_ok=True, parents=True)\n",
    "    cache_image = cache_dir / f\"test_{data['index']}.png\"\n",
    "    if not cache_image.exists():\n",
    "        images = data[\"states\"][data[\"states_mask\"]]\n",
    "        save_image(images, str(cache_image), nrow=images.size(0), pad_value=1.0)\n",
    "    return str(cache_image)\n",
    "\n",
    "\n",
    "def get_text_table(index, data, exp_names):\n",
    "    results = {\"NO.\": list(range(1, len(data[\"text\"]) + 1)), \"GT\": data[\"text\"]}\n",
    "    for exp_name in exp_names:\n",
    "        if exp_name not in details_cache:\n",
    "            exp_id = exp_ids_cache[exp_name]\n",
    "            details_cache[exp_name] = read_jsonlines(\n",
    "                f\"{LOG_ROOT}/{exp_id}/detail.jsonl\"\n",
    "            )\n",
    "        results[exp_name] = details_cache[exp_name][index][\"preds\"]\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_metrics_pyplot(index, exp_names):\n",
    "    matplotlib_header(1 / 3)\n",
    "    plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    fig = plt.figure()\n",
    "    results = {\n",
    "        key: [\n",
    "            np.mean(details_cache[exp_name][index][key])\n",
    "            for exp_name in exp_names\n",
    "        ]\n",
    "        for key in metrics\n",
    "    }\n",
    "    n_metrics = len(metrics)\n",
    "    n_exp = len(exp_names)\n",
    "    width = min((1 - 0.1) / n_exp, 0.2)\n",
    "\n",
    "    x = np.arange(n_metrics)\n",
    "    for i, exp_name in enumerate(exp_names):\n",
    "        idx_exp = exp_names.index(exp_name)\n",
    "        plt.bar(\n",
    "            x + width * (i - n_exp / 2 + 0.5),\n",
    "            [results[key][idx_exp] for key in metrics],\n",
    "            width=width,\n",
    "            label=exp_name,\n",
    "        )\n",
    "    plt.xticks(x, metrics)\n",
    "\n",
    "    plt.legend()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_metrics_bokeh(index, exp_names):\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    results = {\n",
    "        \"exp\": exp_names,\n",
    "    }\n",
    "    results.update(\n",
    "        {\n",
    "            key: [\n",
    "                np.mean(details_cache[exp_name][index][key])\n",
    "                for exp_name in exp_names\n",
    "            ]\n",
    "            for key in metrics\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(results)\n",
    "    source = ColumnDataSource(data=df)\n",
    "\n",
    "    p = figure(\n",
    "        x_range=exp_names,\n",
    "        y_range=(0, 1),\n",
    "        title=\"\",\n",
    "        height=350,\n",
    "        toolbar_location=None,\n",
    "        tools=\"\",\n",
    "    )\n",
    "\n",
    "    n_metrics = len(metrics)\n",
    "    width = min((1 - 0.1) / n_metrics, 0.2)\n",
    "    for i, metric in enumerate(metrics):\n",
    "        p.vbar(\n",
    "            x=dodge(\"exp\", (i - (n_metrics / 2)) * width, range=p.x_range),\n",
    "            top=metric,\n",
    "            width=width,\n",
    "            source=source,\n",
    "            legend_label=metric,\n",
    "        )\n",
    "\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.legend.location = \"top_left\"\n",
    "    p.legend.orientation = \"horizontal\"\n",
    "    return json_item(p)\n",
    "\n",
    "\n",
    "def get_classification_table(index, exp_names):\n",
    "    keys = [\"category_pred\", \"topic_pred\"]\n",
    "    results = {\n",
    "        \"Exp\": exp_names,\n",
    "    }\n",
    "    results.update(\n",
    "        {\n",
    "            key: [\n",
    "                details_cache[exp_name][index][key]\n",
    "                if key in details_cache[exp_name][index]\n",
    "                else \" \"\n",
    "                for exp_name in exp_names\n",
    "            ]\n",
    "            for key in keys\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_metrics_table(index, exp_names):\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    results = {\n",
    "        \"Exp\": exp_names,\n",
    "    }\n",
    "    results.update(\n",
    "        {\n",
    "            key: [\n",
    "                np.mean(details_cache[exp_name][index][key])\n",
    "                for exp_name in exp_names\n",
    "            ]\n",
    "            for key in metrics\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_overall_metrics_table(exp_names):\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    results = {\n",
    "        \"Exp\": exp_names,\n",
    "    }\n",
    "    results.update(\n",
    "        {\n",
    "            key: [\n",
    "                results_cache[exp_name][f\"test/{key}\"]\n",
    "                if exp_name in results_cache\n",
    "                and f\"test/{key}\" in results_cache[exp_name]\n",
    "                else 0.0\n",
    "                for exp_name in exp_names\n",
    "            ]\n",
    "            for key in metrics\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_overall_metrics_pyplot(exp_names):\n",
    "    matplotlib_header(1 / 3)\n",
    "    plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    fig = plt.figure()\n",
    "    results = {\n",
    "        key: [\n",
    "            results_cache[exp_name][f\"test/{key}\"]\n",
    "            if exp_name in results_cache\n",
    "            and f\"test/{key}\" in results_cache[exp_name]\n",
    "            else 0.0\n",
    "            for exp_name in exp_names\n",
    "        ]\n",
    "        for key in metrics\n",
    "    }\n",
    "    n_metrics = len(metrics)\n",
    "    n_exp = len(exp_names)\n",
    "    width = min((1 - 0.1) / n_exp, 0.2)\n",
    "\n",
    "    x = np.arange(n_metrics)\n",
    "    for i, exp_name in enumerate(exp_names):\n",
    "        idx_exp = exp_names.index(exp_name)\n",
    "        plt.bar(\n",
    "            x + width * (i - n_exp / 2 + 0.5),\n",
    "            [results[key][idx_exp] for key in metrics],\n",
    "            width=width,\n",
    "            label=exp_name,\n",
    "        )\n",
    "    plt.xticks(x, metrics)\n",
    "\n",
    "    plt.legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0857e-689f-4a7b-a740-877dce7f7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = get_exp_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f73d2d-cba3-40a3-8a6c-46f83bf28d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\n",
    "    'baseline_cst_clip',\n",
    "    'baseline_glacnet_ViT-L/14',\n",
    "    'baseline_densecap_norm_zero',\n",
    "    'ttnet_sota_v5_base',\n",
    "    'ttnet_sota_v5_0.15_0.5_zero_wclass_0.25_wcat_0.1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb35343-c19c-4d15-b2b5-3d0e24845314",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_name in exp_names:\n",
    "    print(f\"{exp_name}: {exp_ids_cache[exp_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbde63f-993f-4db8-a620-da805f1879f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME = {\n",
    "        \"baseline_cst_clip\": \"CST\", \"baseline_glacnet_ViT-L/14\": \"GLACNet\", \"baseline_densecap_norm_zero\": \"DenseCap\",\n",
    "        \"ttnet_sota_v5_base\": \"TTNet base\", \"ttnet_sota_v5_0.15_0.5_zero_wclass_0.25_wcat_0.1\": \"TTNet\"\n",
    "}\n",
    "def show_result(index):\n",
    "    data = dataset[index]\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=1)\n",
    "    # plt.subplot(211)\n",
    "    \n",
    "    \n",
    "    df = get_text_table(index, data, exp_names)\n",
    "    df = df.rename(columns=RENAME)\n",
    "    \n",
    "    # matplotlib_header(1/3)\n",
    "    width, height = plt.figaspect(1)\n",
    "    plt.rcParams[\"figure.figsize\"] = (16, 16)\n",
    "    plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    # fig = plt.figure()\n",
    "    results = {\n",
    "        key: [\n",
    "            np.mean(details_cache[exp_name][index][key])\n",
    "            for exp_name in exp_names\n",
    "        ]\n",
    "        for key in metrics\n",
    "    }\n",
    "    n_metrics = len(metrics)\n",
    "    n_exp = len(exp_names)\n",
    "    width = min((1 - 0.1) / n_exp, 0.2)\n",
    "\n",
    "    x = np.arange(n_metrics)\n",
    "    for i, exp_name in enumerate(exp_names):\n",
    "        idx_exp = exp_names.index(exp_name)\n",
    "        ax[0].bar(\n",
    "            x + width * (i - n_exp / 2 + 0.5),\n",
    "            [results[key][idx_exp] for key in metrics],\n",
    "            width=width,\n",
    "            label=RENAME[exp_name],\n",
    "        )\n",
    "    ax[0].set_xticks(x, metrics)\n",
    "\n",
    "    ax[0].legend()\n",
    "    # plt.show()\n",
    "    # plt.subplot(212)\n",
    "    img = mpimg.imread(cache_test_image(data))\n",
    "    imgplot = ax[1].imshow(img) \n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    df_1 = df.loc[:,[\"NO.\", \"GT\", \"CST\", \"GLACNet\"]]\n",
    "    table = ax[2].table(cellText=df_1.values, colLabels=df_1.columns, loc='center', bbox=[0,0,1,1], colWidths=[0.1,0.3,0.3,0.3])\n",
    "    df_2 = df.loc[:,[\"NO.\", \"DenseCap\", \"TTNet base\", \"TTNet\"]]\n",
    "    table = ax[3].table(cellText=df_2.values, colLabels=df_2.columns, loc='center', bbox=[0,0,1,1], colWidths=[0.1,0.3,0.3,0.3])\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "    ax[3].set_xticks([])\n",
    "    ax[3].set_yticks([])\n",
    "    # plt.show(imgplot)\n",
    "    fig.savefig(f\"sample/vtt_cases/example_{index}_{CATEGORIES[data['category']]}_{TOPICS[data['topic']]}.jpg\")\n",
    "    plt.close(fig)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4f1d2-7dfb-42fc-b227-bec5085d10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = show_result(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf1e42-a6c9-417d-acea-96bed3d56002",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    show_result(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e10be4-2de5-4fa9-8bd1-60d683987414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_table(index, exp_names):\n",
    "    metrics = [\"BLEU_4\", \"METEOR\", \"ROUGE\", \"CIDEr\", \"BERTScore\"]\n",
    "    results = {\n",
    "        \"Exp\": [RENAME[exp_name] for exp_name in exp_names],\n",
    "    }\n",
    "    results.update(\n",
    "        {\n",
    "            key: [\n",
    "                np.mean(details_cache[exp_name][index][key])\n",
    "                for exp_name in exp_names\n",
    "            ]\n",
    "            for key in metrics\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209f69d-3582-47c9-8140-f1ad8de5cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\n",
    "    'baseline_cst_clip',\n",
    "    'baseline_glacnet_ViT-L/14',\n",
    "    'baseline_densecap_norm_zero',\n",
    "    'ttnet_sota_v5_0.15_0.5_zero_wclass_0.25_wcat_0.1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec5052-4597-4e8d-88f2-4f8dc05530c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce835273-68de-44ca-8644-8599d97a731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_cases():\n",
    "    for index in range(len(dataset)):\n",
    "        data = dataset[index]\n",
    "        df = get_metrics_table(index, exp_names)\n",
    "        if df.CIDEr.argmax() == 3 and df.CIDEr[3] > 6:\n",
    "            name = f\"example_{index}_{CATEGORIES[data['category']]}_{TOPICS[data['topic']]}.jpg\"\n",
    "            print(name)\n",
    "            os.symlink(os.path.join(\"..\", \"vtt_cases\", name), os.path.join(\"sample\", \"vtt_good_cases\", name))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a295c-62fe-46f4-a36d-c5e9bbf13ba0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = good_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f85c6-886e-4af1-8330-cd54e6ff83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CIDEr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab8c03-af30-476d-a8fb-76631e5fafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CIDEr.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b82ac-f670-4cc2-812f-5d233cb9d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_overall_metrics_table(exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf8313-3075-4b33-9926-e2481b630f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_cases():\n",
    "    for index in range(len(dataset)):\n",
    "        data = dataset[index]\n",
    "        df = get_metrics_table(index, exp_names)\n",
    "        if df.CIDEr.argmax() == 3 and df.CIDEr[3] < 6:\n",
    "            name = f\"example_{index}_{CATEGORIES[data['category']]}_{TOPICS[data['topic']]}.jpg\"\n",
    "            print(name)\n",
    "            os.symlink(os.path.join(\"..\", \"vtt_cases\", name), os.path.join(\"sample\", \"vtt_good_cases\", name))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d134f4-2c2c-4b09-b38f-f4f496a1343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = [\n",
    "    'baseline_glacnet_ViT-L/14',\n",
    "    'baseline_densecap_norm_zero',\n",
    "    'ttnet_sota_v5_0.15_0.5_zero_wclass_0.25_wcat_0.1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb33346-e1f6-4b9d-b94d-12c2c600039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME = {\n",
    "        \"baseline_cst_clip\": \"CST\", \"baseline_glacnet_ViT-L/14\": \"GLACNet\", \"baseline_densecap_norm_zero\": \"DenseCap\",\n",
    "        \"ttnet_sota_v5_base\": \"TTNet base\", \"ttnet_sota_v5_0.15_0.5_zero_wclass_0.25_wcat_0.1\": \"TTNet\", \"GT\": \"Groundtruth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a55e7-3948-4836-9db9-8a7ec7506936",
   "metadata": {},
   "outputs": [],
   "source": [
    "great_cases = [143, 220, 262, 295, 308, 358, 412, 1359, 197, 208, 304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afea2e-beeb-41d3-95af-ad3ebe9eef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e96271-ec14-4252-82e3-5a95f8390a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"DenseCap\", \"GLACNet\", \"TTNet\", \"Groundtruth\"]\n",
    "for index in great_cases:\n",
    "    data = dataset[index]\n",
    "    df = get_text_table(index, data, exp_names)\n",
    "    df = df.rename(columns=RENAME)\n",
    "    metrics = get_metrics_table(index, exp_names)\n",
    "    text = \"\"\n",
    "    text += \"\\\\vspace{5pt}\\n\"\n",
    "    text += \"\\\\begin{tiny}\\n\\n\"\n",
    "    print()\n",
    "    print(index)\n",
    "    for model in models:\n",
    "        text += \"\\\\begin{minipage}[c]{0.245\\linewidth}\\n\\n\"\n",
    "        # if model == \"GLACNet\":\n",
    "        #     cite = \"~\\citep{kimGLACNetGLocal2019}\"\n",
    "        # elif model == \"DenseCap\":\n",
    "        #     cite = \"~\\citep{johnsonDenseCapFullyConvolutional2016a}\"\n",
    "        # else:\n",
    "        #     cite = \"\"\n",
    "        cite = \"\"\n",
    "        text += \"\\\\textbf{\"+ model + cite + \":} \\n\\n\"\n",
    "        for i, s in enumerate(df[model]):\n",
    "            if s == df[\"Groundtruth\"][i]:\n",
    "                # text += \"\\\\textcolor{green}{\" f\"[{i+1}] {s.capitalize()}.\" + \"} \"\n",
    "                text += f\"{i+1}. {s.capitalize()}. \"\n",
    "            else:\n",
    "                text += \"\\\\textcolor{red}{\" f\"{i+1}. {s.capitalize()}.\" + \"} \"\n",
    "                # text += f\"[{i+1}] {s.capitalize()}. \"\n",
    "            text += \"\\n\\n\"\n",
    "        # text += f' (CIDEr: {metrics[metrics[\"Exp\"] == model][\"CIDEr\"].values[0]*100:.2f})\\n\\n'\n",
    "        # text += f'\\n\\n'\n",
    "        text += \"\\end{minipage}\\n\"\n",
    "    text += \"\\end{tiny}\\n\"\n",
    "    text += \"\\\\vspace{5pt}\\n\"\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240218e-2ea9-45e6-8317-f644a0008e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.style.hide(axis=\"index\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f05eb-81e1-4b3c-95ee-8e3189e112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b411e5c-65a8-4dc3-b08c-0a2ea0238a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
